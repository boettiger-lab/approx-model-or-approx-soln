---
title: "Pretty darn good control: when are approximate solutions better than approximate models"
titlerunning: Pretty darn good control
thanks: | 
    This material is based upon work supported by the National Science
    Foundation under Grant No. DBI-1942280. 

authors: 
- name: Felipe Montealegre-Mora
  address: Department of Environmental Science, Policy, and Management, University of California, Berkeley
- name: Marcus Laperolerie
  address: Department of Environmental Science, Policy, and Management, University of California, Berkeley
- name: Melissa Chapman
  address: Department of Environmental Science, Policy, and Management, University of California, Berkeley
- name: Carl Boettiger
  address: Department of Environmental Science, Policy, and Management, University of California, Berkeley
  email: cboettig@berkele.edu 


keywords:
- Optimal Control
- Reinforcement Learning
- Uncertainty
- Decision Theory

#PACS: 
#- PAC1
#- superPAC
    
MSC:
- MSC code 1
- MSC code 2

abstract: |
  The text of your abstract.  150 -- 250 words.

bibliography: bibliography.bib
biblio-style: spphys

# bibstyle options spbasic(default), spphys, spmpsci
output: rticles::springer_article

---

# Introduction {#intro}

<!-- Your text comes here. Separate text sections with \cite{Mislevy06Cog}. -->

# Reinforcement learning {#sec:DRL}

Reinforcement learning (RL) is a way of approaching *control problems* through machine learning.
An RL application can be conceptually separated into two parts: an *agent*, and an *environment*.
The agent may *act* on the environment.
This produces two effects: on the one hand, the state of the environment is changed, and on the other, the agent receives a *reward* (see Fig. ).
The reward depends on what action the agent chose, and on the initial and final states of the environment.
The reward encodes the goal which we desire the agent to acheive---in other words, it encodes how we wish the agent controls the environment.
The main part of any RL algorithm is then to progressively improve the agent's *policy*, the function the agent uses to choose which action to take given the state of the environment.
This is done by aggregating experience and learning from it.




# Sustainable fishery management {#sec:fishery}

# Results

# Discussion

<!-- Text with citations by \cite{Galyardt14mmm}.

## Subsection title {#sec:2}

as required. Don't forget to give each section
and subsection a unique label (see Sect. \ref{sec:1}).

#### Paragraph headings 

Use paragraph headings as needed.

\begin{align}
a^2+b^2=c^2
\end{align} -->

## Acknowledgements

The title of this piece references a mathematical biology workshop at NIMBioS
organized by Paul Armsworth, Alan Hastings, Megan Donahue, and Carl Towes in
2011 that first posed the question addressed here.

# References

