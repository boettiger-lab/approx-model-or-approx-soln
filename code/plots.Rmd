---
output: github_document
---

This notebook generates plots from the `.csv` results produced by the corresponding python scripts.  We compare policies across constant effort (MSY-like policies), constant escapement, and the RL agent (PPO).


```{r setup}
library(tidyverse)

best_reward <- function(df) {
  df |> 
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward), sd = sd(reward)) |> 
  filter(mean_reward == max(mean_reward))
}
```


# Constant Mortality

```{r}
msy <- read_csv("../data/msy.csv.xz")
best <- best_reward(msy)
best
```

```{r}
# we don't realize all states at each possible action during simulation
msy |> mutate(X = X+1) |>
 # distinct(action, X) |>
  filter(action == best$action) |>
  mutate(harvest = action * X) |>
  ggplot(aes(X, harvest, col=action, group=action)) + geom_point()

expand_grid(mortality = seq(0,.1, length.out = 20),
            state = seq(0,1, length.out=100)) |> 
  mutate(case = "grid") |> 
  bind_rows(tibble(mortality = best$action, 
                   state= seq(0,1, length.out=100),
                   case = "optimal")) |>
  mutate(harvest = mortality * state) |>
  ggplot(aes(state, harvest, col=case, group=mortality)) +
  geom_line(show.legend = FALSE, lwd=1.5, alpa=0.8) + 
  scale_color_manual(values=c("grey60", "darkblue"))
```


```{r}
rewards <- msy |>
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward)) 

rewards |>
  ggplot(aes(action, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4)
```


```{r}
msy_sim <- msy |>
    filter(action == best$action) |> 
    group_by(rep) |>
    pivot_longer(c("X", "Y", "Z"),
                names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1) # natural units

msy_sim
```


```{r}
msy_sim |>
    filter(rep < 5) |>
    ggplot(aes(t, abundance,  col=species, group =interaction(rep,species)))+ 
        geom_line() + facet_wrap(~rep)

```


```{r}
msy_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()
```
# TAC

80% of  MSY

```{r}
# determine which action is 80% of MSY
actions <- unique(msy$action)
i <- which.min(abs(actions - best$action* 0.8))
```


```{r}
tac_sim <- msy |> 
  filter(action == actions[[i]]) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance")
tac_sim |>
  filter(rep < 20) |>
  ggplot(aes(t, abundance,  col=species)) + 
    geom_line() + facet_wrap(~rep)

```
```{r}
tac_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()
```

# PPO Agent


```{r}
ppo <- read_csv("../data/PPO250.csv.gz")
```
```{r}
ppo_sim <- ppo |> 
  mutate(escapement = (X+1) - action * (X+1),
         effort = action) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance") |>
  mutate(abundance = abundance + 1)
```



```{r}
ppo_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()

ppo_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |> 
  ungroup() |>
  summarise(mean = mean(reward))
```


```{r}
ppo_sim |>
  filter(rep < 4) |>
  ggplot(aes(t, abundance, col=species)) +
  geom_line(alpha=0.6) + facet_wrap(~rep)
```


```{r}
ppo |>
  mutate(X = X+1, Z = Z+1, Z = round(Z, 1)) |>
  distinct(action, X, Z) |> 
  mutate(harvest = action * X) |>
  ggplot(aes(X, harvest, group=Z, color=Z)) +
  geom_smooth(se=FALSE, method=lm,  formula = y ~ splines::ns(x, 6)) +
  geom_point(alpha=0.6, shape="+")



```


```{r}
ppo |>
  mutate(X = X+1, Z = Z+1, Z = round(Z, 1)) |>
  distinct(action, X, Z) |> 
  mutate(harvest = action * X,
         escapement = X - harvest) |>
  ggplot(aes(X, escapement, group=Z, color=Z)) +
  #geom_smooth(se=FALSE, method=lm,  formula = y ~ splines::ns(x, 6)) +
  geom_point(alpha=0.6, shape="+")


```




```{r}
overall_ppo <- 
  ppo |> 
  group_by(rep) |>
  filter(t==max(t)) |> ungroup() |>
  filter(reward > 0) |>
  summarise(reward = mean(reward),
            t = mean(t),
            effort = mean(action)) |>
  mutate(policy="ppo")
overall_ppo
```








# Constant Escapement

```{r}
escapement <- read_csv("../data/escapement.csv.xz", show_col_types = FALSE)
## Determine which level of constant escapement gives highest net reward
best_e <- best_reward(escapement)
best_e
```

```{r}
esc_sims <- escapement |> 
  filter(action == best_e$action) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance") |>
  mutate(abundance = abundance + 1) |>
  rename(escapement = action)

esc_sims |>
  filter(rep < 4) |>
  ggplot(aes(t, abundance, col=species)) + geom_line() +
  geom_line(aes(t, escapement), col="grey50") +
  facet_wrap(~rep)
```


```{r}
rewards <- escapement |>
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward)) 

rewards |>
  ggplot(aes(action, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4)
```





