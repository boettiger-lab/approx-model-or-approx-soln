---
output: github_document
---

This notebook generates plots from the `.csv` results produced by the corresponding python scripts.  We compare policies across constant effort (MSY-like policies), constant escapement, and the RL agent (PPO).

<!-- Basic setup -->
```{r setup}
library(tidyverse)
library(patchwork)
library(RColorBrewer)
```

<!-- Data sources -->
```{r}
# for best const mortality and best const escapement
msy_optimizer <- function(df) {
  df |> 
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward), sd = sd(reward)) |> 
  filter(mean_reward == max(mean_reward))
}
escapement_optimizer <- function(df) {
  df |> 
  group_by(escapement, rep) |>
  filter(t == max(t)) |> 
  group_by(escapement) |>
  summarise(mean_reward = mean(reward), sd = sd(reward)) |> 
  filter(mean_reward == max(mean_reward))
}

# Collect data (outsource to separate R script later TBD)
msy_df <- read_csv("../data/msy.csv.xz")
best_action <- msy_optimizer(msy_df)$action
escapement_df <- read_csv("../data/escapement.csv.xz", show_col_types = FALSE)
best_e <- escapement_optimizer(escapement_df)$escapement
ppo_df <- read_csv("../data/PPO200.csv.xz")

opt_escapement <- escapement_df |> filter(escapement == best_e)

# set up for plots:

msy_sim <- msy_df |>
    filter(action == best_action) |> 
    group_by(rep) |>
    pivot_longer(c("X", "Y", "Z"),
                names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "msy") # natural units, policy name

actions <- unique(msy_df$action)
i <- which.min(abs(actions - best_action* 0.8))
tac_sim <- msy_df |> 
    filter(action == actions[[i]]) |>
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "tac")

ppo_sim <- ppo_df |> 
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "ppo")

esc_sim_df <- escapement_df |> 
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1)

msy_tac_ppo <- bind_rows(msy_sim, tac_sim, ppo_sim)
```

```{r}
#| label: tuning
#| fig.cap : "Result of the tuning procedure for the constant mortality strategy. 
#| (A) Mean episode reward (averaged over 50 episodes) shown as scatter data, and shaded in gray are two standard deviations around each scatter point. Vertical lines correspond to the optimal constant mortality rate $M^* = $ 0.045 (green) and $0.8 M^*=$ 0.036 (violet). 
#| (B) Several constant mortality policies shown for illustrative purposes. Slopes $0.02$, $0.03$, $0.055$ and $0.065$ shown in black; the optimal linear policy $M^*X$ shown in green, while $0.8M^*X$ shown in violet." 
#| out.width : "6.5in"
msy_rewards <- msy_df |>
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward))

rmsy <- msy_rewards |>
  ggplot(aes(action, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4) +
  labs(y = "episode reward", x = "constant mortality") +
  theme(aspect.ratio = 1/1) + 
  geom_vline(aes(xintercept=best_action), color="seagreen3", size=1) + 
  geom_vline(aes(xintercept=0.8*best_action), color="violetred3", size=1) +
  theme_bw() + 
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        aspect.ratio = 1) 

# linear function blueprint
linear_f <- function(slope, x) slope*x
# generates linear function with given slope
linear_f_gen <- function(slope) (function(x) slope*x)

# dummy data set to keep ggplot happy
p <- ggplot(data = data.frame(x = 0), mapping = aes(x = x))

# p + stat_function(fun = linear_f_gen(0.5)) + xlim(0,2)
lines <- p + stat_function(fun = linear_f_gen(0.009)) + 
  stat_function(fun = linear_f_gen(0.018)) +
  stat_function(fun = linear_f_gen(0.027)) +
  stat_function(fun = linear_f_gen(0.8*best_action), col = "violetred3", size=1) +
  stat_function(fun = linear_f_gen(best_action), col = "seagreen3", size=1) +
  stat_function(fun = linear_f_gen(0.054)) + 
  stat_function(fun = linear_f_gen(0.063)) +
  stat_function(fun = linear_f_gen(0.072)) +
  stat_function(fun = linear_f_gen(0.081)) +
  stat_function(fun = linear_f_gen(0.090)) +
  xlim(0,2) +
  xlab("X") + ylab("harvest") +
  theme_bw() +
  theme(#panel.grid.major = element_blank(), 
        #panel.grid.minor = element_blank(), 
        aspect.ratio = 1)


(rmsy | lines) + plot_annotation(tag_levels = c('A'))
```


<!-- Resuts figures -->

```{r} 
#| label: timeseries 
#| fig.cap: "A sample time series for the three fish populations, with the system being controlled, respectively, by the MSY optimal mortality, by $80$ percent of the MSY optimal mortality, and by DRL." 
#| out.width: "6.5in"
policy_labels <- list("msy" = "MSY Const. Mortality", "tac"= "80% MSY Const. Mortality", "ppo"= "DRL")
policy_labeller <- function(variable,value){
  return(policy_labels[value])
}
msy_tac_ppo |> 
    group_by(rep, policy) |>
    filter(rep == 6) |>
    ggplot(aes(t, abundance, col = species)) + 
        geom_line()  + 
        scale_color_manual(values=c('palegreen3', 'coral1', 'deepskyblue4')) +
        facet_wrap(~factor(policy, levels = c("msy", "tac", "ppo")), labeller = policy_labeller ) +
        labs(y = "abundance", x = "time") +
        theme_bw() +
        theme(aspect.ratio = 2/3)
```

```{r} 
#| label: rew_len_fig
#| fig.cap: "Bar charts for the episode lengths (top panel) and episode total harvests (bottom panel) for 50 episodes." 
#| out.width: "6.5in"
p1 <- msy_tac_ppo |> 
    group_by(rep, policy) |>
    filter(t==max(t), species == "X", rep < 50) |>
    ggplot(aes(rep, t)) + 
      geom_col() +
      facet_wrap(~factor(policy, levels = c("msy", "tac", "ppo")), labeller = policy_labeller ) +
      labs(y = "episode length", x = "repetition") +
      theme_bw() + 
      theme(axis.text.x = element_blank())

p2 <- msy_tac_ppo |> 
    group_by(rep, policy) |>
    filter(t==max(t), species == "X", rep < 50) |>
    ggplot(aes(rep, reward)) + 
      geom_col() +
      facet_wrap(~factor(policy, levels = c("msy", "tac", "ppo")), labeller = policy_labeller ) +
      labs(y = "episode harvest", x = "repetition") +
      theme_bw() + 
      theme(axis.text.x = element_blank())

(p1 / p2) + plot_annotation(tag_levels = 'A')
```

```{r}
#| label: action-X
#| fig.cap: "(A-B) Harvest and escapement scatter data for the DRL policy together with the optimal constant escapement (pink) and constant mortality (green) policies for comparison. 
#| (A) includes $Y$ dependence through color, whereas (B) includes $Z$ dependence similarly.
#| (B-C) escapement (i.e. $X_t - h_t$) scatter data for the DRL policy. 
#| Optimal constant escapement policy shown in pink for comparison."
#| out.width: "6.5in"
opt_escapement_harvest <- function(X) case_when(
  X > best_e ~ X - best_e,
  X <= best_e ~ 0
)

opt_escapement_escapement <- function(X) case_when(
  X <= best_e ~ X,
  X > best_e ~ best_e
)

msy_harvest <- function(X) best_action*X
tac_harvest <- function(X) 0.8*msy_harvest(X)

py <- ppo_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, harvest = action*X) |>
  ggplot(aes(X, harvest, color = Y)) +
  geom_point() +
  theme_bw() + 
  theme(aspect.ratio = 1/1) +
  stat_function(fun = opt_escapement_harvest, col = 'deeppink', size = 0.7) + 
  stat_function(fun = msy_harvest, col = 'seagreen2', size = 0.7)

pz <- ppo_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, harvest = action*X) |>
  ggplot(aes(X, harvest, color = Z)) +
  geom_point() +
  theme_bw() + 
  theme(aspect.ratio = 1/1) +
  stat_function(fun = opt_escapement_harvest, col = 'deeppink', size = 0.7) + 
  stat_function(fun = msy_harvest, col = 'seagreen2', size = 0.7)

escxy <- ppo_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, escapement = (1-action)*X) |>
  ggplot(aes(X, escapement, color = Y)) +
  geom_point() +
  theme_bw() + 
  theme(aspect.ratio = 1/1) +
  stat_function(fun = opt_escapement_escapement, col = 'deeppink', size = 0.7)

escxz <- ppo_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, escapement = (1-action)*X) |>
  ggplot(aes(X, escapement, color = Z)) +
  geom_point() +
  theme_bw() + 
  theme(aspect.ratio = 1/1) +
  stat_function(fun = opt_escapement_escapement, col = 'deeppink', size = 0.7)

((py | pz)/ (escxy | escxz)) + plot_annotation(tag_levels = c('A'))
```
```{r}
#| label: state-space
#| fig.cap: "Policy heatmaps. Each policy, say, $\\pi$, was evaluated at points $(x,y,z)$ visited during any of the 50 evaluation rounds. We projected this data down to the $X$-$Y$ plane---i.e. we plotted the heatmap $\\pi(x,y,z)$ as a function of $x$ and $y$."
#| out.width: "6.5in"
i_tac <- which.min(abs(actions - best_action * 0.8))

# color pallette limits
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_colour_gradientn(colours = myPalette(100), limits=c(0,0.25))

pmsy <- msy_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, harvest = action * X) |>
  filter(action == best_action) |>
  ggplot(aes(X, Y, color = harvest)) +
  geom_point() + sc +
  xlim(0,1) +
  ylim(0,0.85) +
  theme_bw() + 
  ggtitle("Opt. Const. Mortality")

ptac <- msy_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, harvest = action * X) |>
  filter(action == actions[[i_tac]]) |>
  ggplot(aes(X, Y, color = harvest)) +
  geom_point() + sc +
  xlim(0,1) +
  ylim(0,0.85) +
  theme_bw() + 
  ggtitle("80% Opt. Const. Mortality")

pppo <- ppo_df |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, harvest = action * X) |>
  ggplot(aes(X, Y, color = harvest)) +
  geom_point() + sc +
  xlim(0,1) +
  ylim(0,0.85) +
  theme_bw() + 
  ggtitle("DRL")

pesc <- opt_escapement |>
  mutate(X = X+1, Y = Y+1, Z = Z+1, 
        harvest = case_when(
          X - escapement > 0 ~ X - escapement,
          X - escapement <= 0 ~  0)
         ) |> 
  ggplot(aes(X, Y, color = harvest)) +
  geom_point() + sc +
  xlim(0,1) +
  ylim(0,0.85) +
  theme_bw() + 
  ggtitle("Opt. Const. Escapement")

(
  (pmsy | ptac) / (pppo | pesc) +
  plot_layout(guides = "collect") & theme(legend.position = 'right')
) + 
  plot_annotation(tag_levels = c('A'))
```


<!-- Appendices -->


<!-- time series -->
```{r} 
#| label: timeseries_msy
#| fig.cap: "Nine time series of the system controlled by the MSY constant mortality policy." 
#| out.width: "6.5in"
msy_tac_ppo |> 
    group_by(rep) |>
    filter(rep < 9, policy == "msy") |>
    ggplot(aes(t, abundance, col = species)) + 
        geom_line()  + 
        scale_color_manual(values=c('palegreen3', 'coral1', 'deepskyblue4')) +
        facet_wrap(~factor(rep)) +
        labs(y = "abundance", x = "time") +
        theme_bw() + 
        theme(aspect.ratio = 0.5)
```

```{r} 
#| label: timeseries_tac
#| fig.cap: "Nine time series of the system controlled by the policy using 80 percent of the MSY constant mortality." 
#| out.width: "6.5in"
msy_tac_ppo |> 
    group_by(rep) |>
    filter(rep < 9, policy == "tac") |>
    ggplot(aes(t, abundance, col = species)) + 
        geom_line()  + 
        scale_color_manual(values=c('palegreen3', 'coral1', 'deepskyblue4')) +
        facet_wrap(~factor(rep)) +
        labs(y = "abundance", x = "time") +
        theme_bw() + 
        theme(aspect.ratio = 0.5)
```

```{r} 
#| label: timeseries_ppo
#| fig.cap: "Nine time series of the system controlled by the trained DRL agent." 
#| out.width: "6.5in"
msy_tac_ppo |> 
    group_by(rep) |>
    filter(rep < 9, policy == "ppo") |>
    ggplot(aes(t, abundance, col = species)) + 
        geom_line()  + 
        scale_color_manual(values=c('palegreen3', 'coral1', 'deepskyblue4')) +
        facet_wrap(~factor(rep)) +
        labs(y = "abundance", x = "time") +
        theme_bw() + 
        theme(aspect.ratio = 0.5)
```

```{r} 
#| label: timeseries_esc
#| fig.cap: "Nine time series of the system controlled by the optimal constant escapement policy." 
#| out.width: "6.5in"
esc_sim_df |> 
    group_by(rep) |>
    filter(rep < 9, escapement == best_e) |>
    ggplot(aes(t, abundance, col = species)) + 
        geom_line()  + 
        scale_color_manual(values=c('palegreen3', 'coral1', 'deepskyblue4')) +
        facet_wrap(~factor(rep)) +
        labs(y = "abundance", x = "time") +
        theme_bw() + 
        theme(aspect.ratio = 0.5)
```


<!-- msy scale downs -->

```{r}
#| label: several-tac
#| fig.cap: "Performance of constant mortality policies with mortality $\\alpha M^*$ for several values of $\\alpha$.
#| The top panel displays the episode lengths for each repetition, while the bottom pannel displays the episode harvest.
#| The labels in the plots are the value of $\\alpha$ expressed as a percentage."
#| out.width: "6.5in"
N <- 30
actions <- unique(msy_df$action)
i85 <- which.min(abs(actions - best_action* 0.85))
i90 <- which.min(abs(actions - best_action* 0.90))
i95 <- which.min(abs(actions - best_action* 0.95))
tac_85_sim <- msy_df |> 
    filter(action == actions[[i85]]) |>
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "85%")
tac_90_sim <- msy_df |> 
    filter(action == actions[[i90]]) |>
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "90%")
tac_95_sim <- msy_df |> 
    filter(action == actions[[i95]]) |>
    pivot_longer(c("X", "Y", "Z"),
        names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1, policy = "95%")

tac_80_sim <- tac_sim |> mutate(policy = "80%")

tac4 <- bind_rows(tac_80_sim, tac_85_sim, tac_90_sim, tac_95_sim)

p1 <- tac4 |> 
    group_by(rep, policy) |>
    filter(t==max(t), species == "X", rep < N) |>
    ggplot(aes(rep, t)) + 
      geom_col() +
      facet_wrap(~factor(policy), ncol = 4) +
      labs(y = "episode length", x = "repetition") +
      theme_bw() + 
      theme(axis.text.x = element_blank())

p2 <- tac4 |> 
    group_by(rep, policy) |>
    filter(t==max(t), species == "X", rep < N) |>
    ggplot(aes(rep, reward)) + 
      geom_col() +
      facet_wrap(~factor(policy), ncol=4) +
      labs(y = "episode harvest", x = "repetition") +
      theme_bw() + 
      theme(axis.text.x = element_blank())

(p1 / p2)
```

<!-- escapement tuning and evaluation -->

```{r}
#| label: esc-tuning-eval
#| fig.cap: "(Left panel) Tuning results for constant escapement policies: mean episode reward scatter data (averaged over 50 episodes) together with two standard deviations shaded in grey. 
#| The optimal escapement level (the one producing maximum mean harvest) is $X_{\\text{esc.}}=0.62$.
#| (Middle and right panels) Reward histograms for the optimal constant escapement policy (middle) and for the DRL policy (right).
#| For both DRL and optimal constant escapement, no early episode ends are observed (i.e. all episodes last for 200 time steps)."
#| out.width: "6.5in"
#| fig.align: "center"
esc_rewards <- escapement_df |>
  group_by(escapement, rep) |>
  filter(t == max(t)) |> 
  group_by(escapement) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward))

resc <- esc_rewards |>
  ggplot(aes(escapement, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4) +
  labs(y = "episode reward", x = "constant escapement") +
  theme_bw() +
  theme(aspect.ratio = 1/1)

esc_len <- esc_sim_df |>
  group_by(rep) |>
  filter(t==max(t), species == "X", escapement == best_e, rep < 50) |>
  ggplot(aes(rep, t)) + 
      geom_col() +
      labs(y = "episode length", x = "repetition") +
      theme_bw() + 
      theme(axis.text.x = element_blank())

esc_rew <- esc_sim_df |>
  group_by(rep) |>
  filter(t==max(t), species == "X", escapement == best_e, rep < 50) |>
  ggplot(aes(rep, reward)) + 
      geom_col() +
      labs(y = "episode harvest", x = "repetition", title = "Escapement") +
      ylim(0,12.8) +
      #ggtitle("Escapement") + 
      theme_bw() + 
      theme(axis.text.x = element_blank(), plot.title = element_text(hjust = 0.5))

drl_rew <- msy_tac_ppo |> 
    group_by(rep, policy) |>
    filter(t==max(t), species == "X", policy == "ppo", rep < 50) |>
    ggplot(aes(rep, reward)) + 
      geom_col() +
      labs(y = "episode harvest", x = "repetition", title = "DRL") +
      ylim(0,12.8) +
      #ggtitle("DRL") + 
      theme_bw() + 
      theme(axis.text.x = element_blank(), plot.title = element_text(hjust = 0.5))

(resc | esc_rew | drl_rew)
```

<!-- Old code blocks: -->


```{r setup}
library(tidyverse)

best_reward <- function(df) {
  df |> 
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward), sd = sd(reward)) |> 
  filter(mean_reward == max(mean_reward))
}
```


# Constant Mortality

```{r}
msy <- read_csv("../data/msy.csv.xz")
best <- best_reward(msy)
best
```

```{r}
# we don't realize all states at each possible action during simulation
msy |> mutate(X = X+1) |>
 # distinct(action, X) |>
  filter(action == best$action) |>
  mutate(harvest = action * X) |>
  ggplot(aes(X, harvest, col=action, group=action)) + geom_point()

expand_grid(mortality = seq(0,.1, length.out = 20),
            state = seq(0,1, length.out=100)) |> 
  mutate(case = "grid") |> 
  bind_rows(tibble(mortality = best$action, 
                   state= seq(0,1, length.out=100),
                   case = "optimal")) |>
  mutate(harvest = mortality * state) |>
  ggplot(aes(state, harvest, col=case, group=mortality)) +
  geom_line(show.legend = FALSE, lwd=1.5, alpa=0.8) + 
  scale_color_manual(values=c("grey60", "darkblue"))
```


```{r}
rewards <- msy |>
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward)) 

rewards |>
  ggplot(aes(action, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4)
```


```{r}
msy_sim <- msy |>
    filter(action == best$action) |> 
    group_by(rep) |>
    pivot_longer(c("X", "Y", "Z"),
                names_to = "species", values_to = "abundance") |>
    mutate(abundance = abundance + 1) # natural units

msy_sim
```


```{r}
msy_sim |>
    filter(rep < 5) |>
    ggplot(aes(t, abundance,  col=species, group =interaction(rep,species)))+ 
        geom_line() + facet_wrap(~rep)

```


```{r}
msy_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()
```
# TAC

80% of  MSY

```{r}
# determine which action is 80% of MSY
actions <- unique(msy$action)
i <- which.min(abs(actions - best$action* 0.8))
```


```{r}
tac_sim <- msy |> 
  filter(action == actions[[i]]) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance")
tac_sim |>
  filter(rep < 20) |>
  ggplot(aes(t, abundance,  col=species)) + 
    geom_line() + facet_wrap(~rep)

```
```{r}
tac_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()
```

# PPO Agent


```{r}
ppo <- read_csv("../data/PPO200.csv.xz")
```
```{r}
ppo_sim <- ppo |> 
  mutate(escapement = (X+1) - action * (X+1),
         effort = action) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance") |>
  mutate(abundance = abundance + 1)
```



```{r}
ppo_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |>
  ggplot(aes(rep, reward)) + geom_col()

ppo_sim |> 
  group_by(rep) |>
  filter(t==max(t), species=="X") |> 
  ungroup() |>
  summarise(mean = mean(reward))
```


```{r}
ppo_sim |>
  filter(rep < 4) |>
  ggplot(aes(t, abundance, col=species)) +
  geom_line(alpha=0.6) + facet_wrap(~rep)
```


```{r}
ppo |>
  mutate(X = X+1, Z = Z+1, Z = round(Z, 1)) |>
  distinct(action, X, Z) |> 
  mutate(harvest = action * X) |>
  ggplot(aes(X, harvest, group=Z, color=Z)) +
  geom_smooth(se=FALSE, method=lm,  formula = y ~ splines::ns(x, 6)) +
  geom_point(alpha=0.6, shape="+")



```


```{r}
ppo |>
  mutate(X = X+1, Z = Z+1, Z = round(Z, 1)) |>
  distinct(action, X, Z) |> 
  mutate(harvest = action * X,
         escapement = X - harvest) |>
  ggplot(aes(X, escapement, group=Z, color=Z)) +
  #geom_smooth(se=FALSE, method=lm,  formula = y ~ splines::ns(x, 6)) +
  geom_point(alpha=0.6, shape="+")


```




```{r}
overall_ppo <- 
  ppo |> 
  group_by(rep) |>
  filter(t==max(t)) |> ungroup() |>
  filter(reward > 0) |>
  summarise(reward = mean(reward),
            t = mean(t),
            effort = mean(action)) |>
  mutate(policy="ppo")
overall_ppo
```








# Constant Escapement

```{r}
escapement <- read_csv("../data/escapement.csv.xz", show_col_types = FALSE)
## Determine which level of constant escapement gives highest net reward
best_e <- best_reward(escapement)
best_e
```

```{r}
esc_sims <- escapement |> 
  filter(action == best_e$action) |>
  pivot_longer(c("X", "Y", "Z"),
               names_to = "species", values_to = "abundance") |>
  mutate(abundance = abundance + 1) |>
  rename(escapement = action)

esc_sims |>
  filter(rep < 4) |>
  ggplot(aes(t, abundance, col=species)) + geom_line() +
  geom_line(aes(t, escapement), col="grey50") +
  facet_wrap(~rep)
```


```{r}
rewards <- escapement |>
  group_by(action, rep) |>
  filter(t == max(t)) |> 
  group_by(action) |>
  summarise(mean_reward = mean(reward),
            sd = sd(reward)) 

rewards |>
  ggplot(aes(action, mean_reward, 
             ymin = mean_reward - 2*sd,
             ymax=mean_reward+2*sd)) +
  geom_point() + geom_ribbon(alpha=0.4)
```





